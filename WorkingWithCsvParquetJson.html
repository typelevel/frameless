<!DOCTYPE html>
<html lang="en">
  
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="Typelevel Laika + Helium Theme" />
  <title>Working with CSV and Parquet data</title>
  
  <meta name="author" content="Olivier Blanvillain"/>
  
  <meta name="author" content="Adelbert Chang"/>
  
  <meta name="author" content="Marios Iliofotou"/>
  
  <meta name="author" content="Gleb Kanterov"/>
  
  <meta name="author" content="Erik Osheim"/>
  
  <meta name="author" content="Jeremy Smith"/>
  
  <meta name="author" content="CÃ©dric Chantepie"/>
  
  <meta name="author" content="Grigory Pomadchin"/>
  
  
  <meta name="description" content="docs"/>
  
  
  
  <link rel="icon" sizes="32x32" type="image/png" href="https://typelevel.org/img/favicon.png"/>
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700">
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Mono:500">
  
  <link rel="stylesheet" type="text/css" href="helium/icofont.min.css" />
    <link rel="stylesheet" type="text/css" href="helium/laika-helium.css" />
  
  <script src="helium/laika-helium.js"></script>
  
  
  
  <script> /* for avoiding page load transitions */ </script>
</head>

  <body>

    <header id="top-bar" class="light-default dark-default">

  <div class="row">
    <a id="nav-icon">
      <i class="icofont-laika navigationMenu" title="Navigation">&#xefa2;</i>
    </a>
    
    
  </div>

  <a class="image-link" href="https://typelevel.org"><img src="https://typelevel.org/img/logo.svg"></a>

  <div class="row links">
    
    <a class="icon-link svg-link" href="https://github.com/typelevel/frameless"><span class="github" title="Source Code"><svg class="svg-icon" width="100%" height="100%" viewBox="0 0 100 100" version="1.1" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
  <g class="svg-shape">
    <path d="M49.995,1c-27.609,-0 -49.995,22.386 -49.995,50.002c-0,22.09 14.325,40.83 34.194,47.444c2.501,0.458 3.413,-1.086 3.413,-2.412c0,-1.185 -0.043,-4.331 -0.067,-8.503c-13.908,3.021 -16.843,-6.704 -16.843,-6.704c-2.274,-5.773 -5.552,-7.311 -5.552,-7.311c-4.54,-3.103 0.344,-3.042 0.344,-3.042c5.018,0.356 7.658,5.154 7.658,5.154c4.46,7.64 11.704,5.433 14.552,4.156c0.454,-3.232 1.744,-5.436 3.174,-6.685c-11.102,-1.262 -22.775,-5.553 -22.775,-24.713c-0,-5.457 1.949,-9.92 5.147,-13.416c-0.516,-1.265 -2.231,-6.348 0.488,-13.233c0,0 4.199,-1.344 13.751,5.126c3.988,-1.108 8.266,-1.663 12.518,-1.682c4.245,0.019 8.523,0.574 12.517,1.682c9.546,-6.47 13.736,-5.126 13.736,-5.126c2.728,6.885 1.013,11.968 0.497,13.233c3.204,3.496 5.141,7.959 5.141,13.416c0,19.209 -11.691,23.436 -22.83,24.673c1.795,1.544 3.394,4.595 3.394,9.26c0,6.682 -0.061,12.076 -0.061,13.715c0,1.338 0.899,2.894 3.438,2.406c19.853,-6.627 34.166,-25.354 34.166,-47.438c-0,-27.616 -22.389,-50.002 -50.005,-50.002"/>
  </g>
</svg></span></a>
    
    <a class="icon-link glyph-link" href="https://discord.gg/XF3CXcMzqD"><i class="icofont-laika chat" title="Chat">&#xeed5;</i></a>
    
    <a class="icon-link svg-link" href="https://fosstodon.org/@typelevel"><span class="mastodon" title="Mastodon"><svg class="svg-icon" width="100%" height="100%" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <g class="svg-shape">
    <path d="M11.19 12.195c2.016-.24 3.77-1.475 3.99-2.603.348-1.778.32-4.339.32-4.339 0-3.47-2.286-4.488-2.286-4.488C12.062.238 10.083.017 8.027 0h-.05C5.92.017 3.942.238 2.79.765c0 0-2.285 1.017-2.285 4.488l-.002.662c-.004.64-.007 1.35.011 2.091.083 3.394.626 6.74 3.78 7.57 1.454.383 2.703.463 3.709.408 1.823-.1 2.847-.647 2.847-.647l-.06-1.317s-1.303.41-2.767.36c-1.45-.05-2.98-.156-3.215-1.928a3.614 3.614 0 0 1-.033-.496s1.424.346 3.228.428c1.103.05 2.137-.064 3.188-.189zm1.613-2.47H11.13v-4.08c0-.859-.364-1.295-1.091-1.295-.804 0-1.207.517-1.207 1.541v2.233H7.168V5.89c0-1.024-.403-1.541-1.207-1.541-.727 0-1.091.436-1.091 1.296v4.079H3.197V5.522c0-.859.22-1.541.66-2.046.456-.505 1.052-.764 1.793-.764.856 0 1.504.328 1.933.983L8 4.39l.417-.695c.429-.655 1.077-.983 1.934-.983.74 0 1.336.259 1.791.764.442.505.661 1.187.661 2.046v4.203z"/>
  </g>
</svg></span></a>
    
  </div>  

</header>
    
    <nav id="sidebar">

  <div class="row">
    
    <a class="icon-link svg-link" href="https://github.com/typelevel/frameless"><span class="github" title="Source Code"><svg class="svg-icon" width="100%" height="100%" viewBox="0 0 100 100" version="1.1" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;">
  <g class="svg-shape">
    <path d="M49.995,1c-27.609,-0 -49.995,22.386 -49.995,50.002c-0,22.09 14.325,40.83 34.194,47.444c2.501,0.458 3.413,-1.086 3.413,-2.412c0,-1.185 -0.043,-4.331 -0.067,-8.503c-13.908,3.021 -16.843,-6.704 -16.843,-6.704c-2.274,-5.773 -5.552,-7.311 -5.552,-7.311c-4.54,-3.103 0.344,-3.042 0.344,-3.042c5.018,0.356 7.658,5.154 7.658,5.154c4.46,7.64 11.704,5.433 14.552,4.156c0.454,-3.232 1.744,-5.436 3.174,-6.685c-11.102,-1.262 -22.775,-5.553 -22.775,-24.713c-0,-5.457 1.949,-9.92 5.147,-13.416c-0.516,-1.265 -2.231,-6.348 0.488,-13.233c0,0 4.199,-1.344 13.751,5.126c3.988,-1.108 8.266,-1.663 12.518,-1.682c4.245,0.019 8.523,0.574 12.517,1.682c9.546,-6.47 13.736,-5.126 13.736,-5.126c2.728,6.885 1.013,11.968 0.497,13.233c3.204,3.496 5.141,7.959 5.141,13.416c0,19.209 -11.691,23.436 -22.83,24.673c1.795,1.544 3.394,4.595 3.394,9.26c0,6.682 -0.061,12.076 -0.061,13.715c0,1.338 0.899,2.894 3.438,2.406c19.853,-6.627 34.166,-25.354 34.166,-47.438c-0,-27.616 -22.389,-50.002 -50.005,-50.002"/>
  </g>
</svg></span></a>
    
    <a class="icon-link glyph-link" href="https://discord.gg/XF3CXcMzqD"><i class="icofont-laika chat" title="Chat">&#xeed5;</i></a>
    
    <a class="icon-link svg-link" href="https://fosstodon.org/@typelevel"><span class="mastodon" title="Mastodon"><svg class="svg-icon" width="100%" height="100%" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <g class="svg-shape">
    <path d="M11.19 12.195c2.016-.24 3.77-1.475 3.99-2.603.348-1.778.32-4.339.32-4.339 0-3.47-2.286-4.488-2.286-4.488C12.062.238 10.083.017 8.027 0h-.05C5.92.017 3.942.238 2.79.765c0 0-2.285 1.017-2.285 4.488l-.002.662c-.004.64-.007 1.35.011 2.091.083 3.394.626 6.74 3.78 7.57 1.454.383 2.703.463 3.709.408 1.823-.1 2.847-.647 2.847-.647l-.06-1.317s-1.303.41-2.767.36c-1.45-.05-2.98-.156-3.215-1.928a3.614 3.614 0 0 1-.033-.496s1.424.346 3.228.428c1.103.05 2.137-.064 3.188-.189zm1.613-2.47H11.13v-4.08c0-.859-.364-1.295-1.091-1.295-.804 0-1.207.517-1.207 1.541v2.233H7.168V5.89c0-1.024-.403-1.541-1.207-1.541-.727 0-1.091.436-1.091 1.296v4.079H3.197V5.522c0-.859.22-1.541.66-2.046.456-.505 1.052-.764 1.793-.764.856 0 1.504.328 1.933.983L8 4.39l.417-.695c.429-.655 1.077-.983 1.934-.983.74 0 1.336.259 1.791.764.442.505.661 1.187.661 2.046v4.203z"/>
  </g>
</svg></span></a>
    
  </div>

  <ul class="nav-list">
    <li class="level1 nav-leaf"><a href="FeatureOverview.html">TypedDataset: Feature Overview</a></li>
    <li class="level1 nav-leaf"><a href="TypedDatasetVsSparkDataset.html">Comparing TypedDatasets with Spark&#39;s Datasets</a></li>
    <li class="level1 active nav-leaf"><a href="#">Working with CSV and Parquet data</a></li>
    <li class="level1 nav-leaf"><a href="Injection.html">Injection: Creating Custom Encoders</a></li>
    <li class="level1 nav-leaf"><a href="Job.html">Job[A]</a></li>
    <li class="level1 nav-leaf"><a href="Cats.html">Using Cats with Frameless</a></li>
    <li class="level1 nav-leaf"><a href="TypedML.html">Typed Spark ML</a></li>
    <li class="level1 nav-leaf"><a href="TypedDataFrame.html">Proof of Concept: TypedDataFrame</a></li>
    <li class="level1 nav-leaf"><a href="TypedEncoder.html">Typed Encoders in Frameless</a></li>
  </ul>

</nav>

    <div id="container">

      
<nav id="page-nav">
  <p class="header"><a href="#">Working with CSV and Parquet data</a></p>

  <ul class="nav-list">
    <li class="level1 nav-node"><a href="#working-with-csv">Working with CSV</a></li>
    <li class="level2 nav-leaf"><a href="#dealing-with-csv-files-with-multiple-columns">Dealing with CSV files with multiple columns</a></li>
    <li class="level1 nav-node"><a href="#working-with-parquet">Working with Parquet</a></li>
    <li class="level2 nav-leaf"><a href="#dealing-with-parquet-files-with-multiple-columns">Dealing with Parquet files with multiple columns</a></li>
  </ul>

  <p class="footer"></p>
</nav>


      <main class="content">

        <h1 id="working-with-csv-and-parquet-data" class="title">Working with CSV and Parquet data</h1>
        <p>You need these imports for most Frameless projects. </p>
        <pre class="keep-together pdf epub"><code class="nohighlight"><span class="keyword">import</span><span> </span><span class="identifier">frameless</span><span>.</span><span class="identifier">_</span><span>
</span><span class="keyword">import</span><span> </span><span class="identifier">frameless</span><span>.</span><span class="identifier">syntax</span><span>.</span><span class="identifier">_</span><span>
</span><span class="keyword">import</span><span> </span><span class="identifier">frameless</span><span>.</span><span class="identifier">functions</span><span>.</span><span class="identifier">aggregate</span><span>.</span><span class="identifier">_</span></code></pre>
        
        <h2 id="working-with-csv" class="section"><a class="anchor-link left" href="#working-with-csv"><i class="icofont-laika link">&#xef71;</i></a>Working with CSV</h2>
        <p>We first load some CSV data and print the schema. </p>
        <pre><code class="nohighlight"><span class="keyword">val</span><span> </span><span class="identifier">df</span><span> = </span><span class="identifier">spark</span><span>.</span><span class="identifier">read</span><span>.</span><span class="identifier">format</span><span>(</span><span class="string-literal">&quot;csv&quot;</span><span>).</span><span class="identifier">load</span><span>(</span><span class="identifier">testDataPath</span><span>)
</span><span class="comment">// df: org.apache.spark.sql.package.DataFrame = [_c0: string, _c1: string ... 3 more fields]
</span><span class="identifier">df</span><span>.</span><span class="identifier">show</span><span>(</span><span class="number-literal">2</span><span>)
</span><span class="comment">// +---+---+---+---+-----------+
// |_c0|_c1|_c2|_c3|        _c4|
// +---+---+---+---+-----------+
// |5.1|3.5|1.4|0.2|Iris-setosa|
// |4.9|3.0|1.4|0.2|Iris-setosa|
// +---+---+---+---+-----------+
// only showing top 2 rows
// 
</span><span class="identifier">df</span><span>.</span><span class="identifier">printSchema</span><span>
</span><span class="comment">// root
//  |-- _c0: string (nullable = true)
//  |-- _c1: string (nullable = true)
//  |-- _c2: string (nullable = true)
//  |-- _c3: string (nullable = true)
//  |-- _c4: string (nullable = true)
//</span></code></pre>
        <p>The easiest way to read from CSV into a <code>TypedDataset</code> is to create a case class that follows 
        the exact number, type, and order for the fields as they appear in the CSV file. This is shown in 
        the example bellow with the use of the <code>Iris</code> case class.</p>
        <pre><code class="nohighlight"><span class="keyword">final</span><span> </span><span class="keyword">case</span><span> </span><span class="keyword">class</span><span> </span><span class="type-name">Iris</span><span>(</span><span class="identifier">sLength</span><span>: </span><span class="type-name">Double</span><span>, </span><span class="identifier">sWidth</span><span>: </span><span class="type-name">Double</span><span>, </span><span class="identifier">pLength</span><span>: </span><span class="type-name">Double</span><span>, </span><span class="identifier">pWidth</span><span>: </span><span class="type-name">Double</span><span>, </span><span class="identifier">kind</span><span>: </span><span class="type-name">String</span><span>)
</span><span class="keyword">val</span><span> </span><span class="identifier">testDataDf</span><span> = </span><span class="identifier">spark</span><span>.</span><span class="identifier">read</span><span>.</span><span class="identifier">format</span><span>(</span><span class="string-literal">&quot;csv&quot;</span><span>).</span><span class="identifier">schema</span><span>(</span><span class="type-name">TypedExpressionEncoder</span><span>[</span><span class="type-name">Iris</span><span>].</span><span class="identifier">schema</span><span>).</span><span class="identifier">load</span><span>(</span><span class="identifier">testDataPath</span><span>)
</span><span class="comment">// testDataDf: org.apache.spark.sql.package.DataFrame = [sLength: double, sWidth: double ... 3 more fields]
</span><span class="keyword">val</span><span> </span><span class="identifier">data</span><span>: </span><span class="type-name">TypedDataset</span><span>[</span><span class="type-name">Iris</span><span>] = </span><span class="type-name">TypedDataset</span><span>.</span><span class="identifier">createUnsafe</span><span>[</span><span class="type-name">Iris</span><span>](</span><span class="identifier">testDataDf</span><span>)
</span><span class="comment">// data: TypedDataset[Iris] = [sLength: double, sWidth: double ... 3 more fields]
</span><span class="identifier">data</span><span>.</span><span class="identifier">show</span><span>(</span><span class="number-literal">2</span><span>).</span><span class="identifier">run</span><span>()
</span><span class="comment">// +-------+------+-------+------+-----------+
// |sLength|sWidth|pLength|pWidth|       kind|
// +-------+------+-------+------+-----------+
// |    5.1|   3.5|    1.4|   0.2|Iris-setosa|
// |    4.9|   3.0|    1.4|   0.2|Iris-setosa|
// +-------+------+-------+------+-----------+
// only showing top 2 rows
//</span></code></pre>
        <p>If we do not explicitly define the schema of the CSV file then the types will not match leading to runtime errors. </p>
        <pre class="keep-together pdf epub"><code class="nohighlight"><span class="keyword">val</span><span> </span><span class="identifier">testDataNoSchema</span><span> = </span><span class="identifier">spark</span><span>.</span><span class="identifier">read</span><span>.</span><span class="identifier">format</span><span>(</span><span class="string-literal">&quot;csv&quot;</span><span>).</span><span class="identifier">load</span><span>(</span><span class="identifier">testDataPath</span><span>)
</span><span class="comment">// testDataNoSchema: org.apache.spark.sql.package.DataFrame = [_c0: string, _c1: string ... 3 more fields]
</span><span class="keyword">val</span><span> </span><span class="identifier">data</span><span>: </span><span class="type-name">TypedDataset</span><span>[</span><span class="type-name">Iris</span><span>] = </span><span class="type-name">TypedDataset</span><span>.</span><span class="identifier">createUnsafe</span><span>[</span><span class="type-name">Iris</span><span>](</span><span class="identifier">testDataNoSchema</span><span>)
</span><span class="comment">// data: TypedDataset[Iris] = [sLength: string, sWidth: string ... 3 more fields]</span></code></pre>
        <pre><code class="nohighlight"><span class="identifier">data</span><span>.</span><span class="identifier">collect</span><span>().</span><span class="identifier">run</span><span>()
</span><span class="comment">// org.apache.spark.SparkRuntimeException: Error while decoding: scala.ScalaReflectionException: &lt;none&gt; is not a term
// newInstance(class repl.MdocSession$MdocApp0$Iris).
// 	at org.apache.spark.sql.errors.QueryExecutionErrors$.expressionDecodingError(QueryExecutionErrors.scala:1543)
// 	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Deserializer.apply(ExpressionEncoder.scala:178)
// 	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Deserializer.apply(ExpressionEncoder.scala:166)
// 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
// 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
// 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
// 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
// 	at scala.collection.TraversableLike.map(TraversableLike.scala:286)
// 	at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
// 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:198)
// 	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4177)
// 	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3418)
// 	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4167)
// 	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526)
// 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4165)
// 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)
// 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)
// 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)
// 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)
// 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)
// 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4165)
// 	at org.apache.spark.sql.Dataset.collect(Dataset.scala:3418)
// 	at frameless.TypedDataset.$anonfun$collect$1(TypedDataset.scala:333)
// 	at frameless.Job$$anon$4.run(Job.scala:38)
// 	at repl.MdocSession$MdocApp0$$anonfun$13.apply(WorkingWithCsvParquetJson.md:85)
// 	at repl.MdocSession$MdocApp0$$anonfun$13.apply(WorkingWithCsvParquetJson.md:85)
// Caused by: scala.ScalaReflectionException: &lt;none&gt; is not a term
// 	at scala.reflect.api.Symbols$SymbolApi.asTerm(Symbols.scala:211)
// 	at scala.reflect.api.Symbols$SymbolApi.asTerm$(Symbols.scala:211)
// 	at scala.reflect.internal.Symbols$SymbolContextApiImpl.asTerm(Symbols.scala:100)
// 	at org.apache.spark.sql.catalyst.ScalaReflection$.findConstructor(ScalaReflection.scala:689)
// 	at org.apache.spark.sql.catalyst.expressions.objects.NewInstance.$anonfun$constructor$1(objects.scala:551)
// 	at org.apache.spark.sql.catalyst.expressions.objects.NewInstance.$anonfun$constructor$5(objects.scala:562)
// 	at scala.Option.getOrElse(Option.scala:189)
// 	at org.apache.spark.sql.catalyst.expressions.objects.NewInstance.constructor$lzycompute(objects.scala:561)
// 	at org.apache.spark.sql.catalyst.expressions.objects.NewInstance.constructor(objects.scala:548)
// 	at org.apache.spark.sql.catalyst.expressions.objects.NewInstance.eval(objects.scala:584)
// 	at org.apache.spark.sql.catalyst.expressions.InterpretedSafeProjection.apply(InterpretedSafeProjection.scala:115)
// 	at org.apache.spark.sql.catalyst.expressions.InterpretedSafeProjection.apply(InterpretedSafeProjection.scala:32)
// 	at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Deserializer.apply(ExpressionEncoder.scala:175)
// 	... 24 more</span></code></pre>
        
        <h3 id="dealing-with-csv-files-with-multiple-columns" class="section"><a class="anchor-link left" href="#dealing-with-csv-files-with-multiple-columns"><i class="icofont-laika link">&#xef71;</i></a>Dealing with CSV files with multiple columns</h3>
        <p>When the dataset has many columns, it is impractical to define a case class that contains many columns we don&#39;t need. 
        In such case, we can project the columns we do need, cast them to the proper type, and then call <code>createUnsafe</code> using a case class
        that contains a much smaller subset of the columns.<br></p>
        <pre><code class="nohighlight"><span class="keyword">import</span><span> </span><span class="identifier">org</span><span>.</span><span class="identifier">apache</span><span>.</span><span class="identifier">spark</span><span>.</span><span class="identifier">sql</span><span>.</span><span class="identifier">types</span><span>.</span><span class="type-name">DoubleType</span><span>
</span><span class="keyword">final</span><span> </span><span class="keyword">case</span><span> </span><span class="keyword">class</span><span> </span><span class="type-name">IrisLight</span><span>(</span><span class="identifier">kind</span><span>: </span><span class="type-name">String</span><span>, </span><span class="identifier">sLength</span><span>: </span><span class="type-name">Double</span><span>)

</span><span class="keyword">val</span><span> </span><span class="identifier">testDataDf</span><span> = </span><span class="identifier">spark</span><span>.</span><span class="identifier">read</span><span>.</span><span class="identifier">format</span><span>(</span><span class="string-literal">&quot;csv&quot;</span><span>).</span><span class="identifier">load</span><span>(</span><span class="identifier">testDataPath</span><span>)
</span><span class="comment">// testDataDf: org.apache.spark.sql.package.DataFrame = [_c0: string, _c1: string ... 3 more fields]
</span><span class="keyword">val</span><span> </span><span class="identifier">projectedDf</span><span> = </span><span class="identifier">testDataDf</span><span>.</span><span class="identifier">select</span><span>(</span><span class="identifier">testDataDf</span><span>(</span><span class="string-literal">&quot;_c4&quot;</span><span>).</span><span class="identifier">as</span><span>(</span><span class="string-literal">&quot;kind&quot;</span><span>), </span><span class="identifier">testDataDf</span><span>(</span><span class="string-literal">&quot;_c1&quot;</span><span>).</span><span class="identifier">cast</span><span>(</span><span class="type-name">DoubleType</span><span>).</span><span class="identifier">as</span><span>(</span><span class="string-literal">&quot;sLength&quot;</span><span>))
</span><span class="comment">// projectedDf: org.apache.spark.sql.package.DataFrame = [kind: string, sLength: double]
</span><span class="keyword">val</span><span> </span><span class="identifier">data</span><span> = </span><span class="type-name">TypedDataset</span><span>.</span><span class="identifier">createUnsafe</span><span>[</span><span class="type-name">IrisLight</span><span>](</span><span class="identifier">projectedDf</span><span>)
</span><span class="comment">// data: TypedDataset[IrisLight] = [kind: string, sLength: double]
</span><span class="identifier">data</span><span>.</span><span class="identifier">take</span><span>(</span><span class="number-literal">2</span><span>).</span><span class="identifier">run</span><span>()
</span><span class="comment">// res5: Seq[IrisLight] = WrappedArray(
//   IrisLight(&quot;Iris-setosa&quot;, 3.5),
//   IrisLight(&quot;Iris-setosa&quot;, 3.0)
// )</span></code></pre>
        
        <h2 id="working-with-parquet" class="section"><a class="anchor-link left" href="#working-with-parquet"><i class="icofont-laika link">&#xef71;</i></a>Working with Parquet</h2>
        <p>Spark is much better at reading the schema from parquet files. </p>
        <pre class="keep-together pdf epub"><code class="nohighlight"><span class="keyword">val</span><span> </span><span class="identifier">testDataParquet</span><span> = </span><span class="identifier">spark</span><span>.</span><span class="identifier">read</span><span>.</span><span class="identifier">format</span><span>(</span><span class="string-literal">&quot;parquet&quot;</span><span>).</span><span class="identifier">load</span><span>(</span><span class="identifier">testDataPathParquet</span><span>)
</span><span class="comment">// testDataParquet: org.apache.spark.sql.package.DataFrame = [sLength: double, sWidth: double ... 3 more fields]
</span><span class="identifier">testDataParquet</span><span>.</span><span class="identifier">printSchema</span><span>
</span><span class="comment">// root
//  |-- sLength: double (nullable = true)
//  |-- sWidth: double (nullable = true)
//  |-- pLength: double (nullable = true)
//  |-- pWidth: double (nullable = true)
//  |-- kind: string (nullable = true)
//</span></code></pre>
        <p>So as long as we use a type (case class) that reflects the same number, type, and order of the fields 
        from the data everything works as expected. </p>
        <pre class="keep-together pdf epub"><code class="nohighlight"><span class="keyword">val</span><span> </span><span class="identifier">data</span><span>: </span><span class="type-name">TypedDataset</span><span>[</span><span class="type-name">Iris</span><span>] = </span><span class="type-name">TypedDataset</span><span>.</span><span class="identifier">createUnsafe</span><span>[</span><span class="type-name">Iris</span><span>](</span><span class="identifier">testDataParquet</span><span>)
</span><span class="comment">// data: TypedDataset[Iris] = [sLength: double, sWidth: double ... 3 more fields]
</span><span class="identifier">data</span><span>.</span><span class="identifier">take</span><span>(</span><span class="number-literal">2</span><span>).</span><span class="identifier">run</span><span>()
</span><span class="comment">// res10: Seq[Iris] = WrappedArray(
//   Iris(5.1, 3.5, 1.4, 0.2, &quot;Iris-setosa&quot;),
//   Iris(4.9, 3.0, 1.4, 0.2, &quot;Iris-setosa&quot;)
// )</span></code></pre>
        
        <h3 id="dealing-with-parquet-files-with-multiple-columns" class="section"><a class="anchor-link left" href="#dealing-with-parquet-files-with-multiple-columns"><i class="icofont-laika link">&#xef71;</i></a>Dealing with Parquet files with multiple columns</h3>
        <p>The main difference compared to CSV is that with Parquet Spark is better at inferring the types. This makes it simpler 
        to project the columns we need without having the cast the to the proper type. </p>
        <pre class="keep-together pdf epub"><code class="nohighlight"><span class="keyword">final</span><span> </span><span class="keyword">case</span><span> </span><span class="keyword">class</span><span> </span><span class="type-name">IrisLight</span><span>(</span><span class="identifier">kind</span><span>: </span><span class="type-name">String</span><span>, </span><span class="identifier">sLength</span><span>: </span><span class="type-name">Double</span><span>)

</span><span class="keyword">val</span><span> </span><span class="identifier">projectedDf</span><span> = </span><span class="identifier">testDataParquet</span><span>.</span><span class="identifier">select</span><span>(</span><span class="string-literal">&quot;kind&quot;</span><span>, </span><span class="string-literal">&quot;sLength&quot;</span><span>)
</span><span class="comment">// projectedDf: org.apache.spark.sql.package.DataFrame = [kind: string, sLength: double]
</span><span class="keyword">val</span><span> </span><span class="identifier">data</span><span> = </span><span class="type-name">TypedDataset</span><span>.</span><span class="identifier">createUnsafe</span><span>[</span><span class="type-name">IrisLight</span><span>](</span><span class="identifier">projectedDf</span><span>)
</span><span class="comment">// data: TypedDataset[IrisLight] = [kind: string, sLength: double]
</span><span class="identifier">data</span><span>.</span><span class="identifier">take</span><span>(</span><span class="number-literal">2</span><span>).</span><span class="identifier">run</span><span>()
</span><span class="comment">// res11: Seq[IrisLight] = WrappedArray(
//   IrisLight(&quot;Iris-setosa&quot;, 5.1),
//   IrisLight(&quot;Iris-setosa&quot;, 4.9)
// )</span></code></pre>

        
<hr class="footer-rule"/>
<footer>
  frameless is a <a href="https://typelevel.org/">Typelevel</a> project distributed under the <a href="http://opensource.org/licenses/Apache-2.0">Apache-2.0</a> license.
</footer>


      </main>

    </div>

  </body>

</html>